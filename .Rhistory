knitr::opts_chunk$set(echo = TRUE)
library(kableExtra)
library(tidyverse) # loads dplyr, ggplot2, and others
library(readr) # more informative and easy way to import data
library(stringr) # to handle text elements
library(tidytext) # includes set of functions useful for manipulating text
library(quanteda) # includes functions to implement Lexicoder
library(textdata)
library(academictwitteR) # for fetching Twitter data
getwd()
tweets  <- readRDS(gzcon(url("https://github.com/cjbarrie/CTA-ED/blob/main/data/sentanalysis/newstweets.rds?raw=true")))
head(tweets)
colnames(tweets)
tweets <- tweets %>%
select(user_username, text, created_at, user_name,
retweet_count, like_count, quote_count) %>%
rename(username = user_username,
newspaper = user_name,
tweet = text)
tweets %>%
arrange(created_at) %>%
tail(5) %>%
kbl() %>%
kable_styling(c("striped", "hover", "condensed", "responsive"))
tidy_tweets <- tweets %>%
mutate(desc = tolower(tweet)) %>%
unnest_tokens(word, desc) %>%
filter(str_detect(word, "[a-z]"))
tidy_tweets <- tidy_tweets %>%
filter(!word %in% stop_words$word)
get_sentiments("afinn")
get_sentiments("bing")
get_sentiments("nrc")
nrc_fear <- get_sentiments("nrc") %>%
filter(sentiment == "fear")
tidy_tweets %>%
inner_join(nrc_fear) %>%
count(word, sort = TRUE)
#gen data variable, order and format date
tidy_tweets$date <- as.Date(tidy_tweets$created_at)
tidy_tweets <- tidy_tweets %>%
arrange(date)
tidy_tweets$order <- 1:nrow(tidy_tweets)
tweets_nrc_sentiment %>%
ggplot(aes(date, sentiment)) +
geom_point(alpha=0.5) +
geom_smooth(method= loess, alpha=0.25)
tweets_nrc_sentiment <- tidy_tweets %>%
inner_join(get_sentiments("nrc")) %>%
count(date, index = order %/% 1000, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
tweets_nrc_sentiment %>%
ggplot(aes(date, sentiment)) +
geom_point(alpha=0.5) +
geom_smooth(method= loess, alpha=0.25)
tidy_tweets %>%
inner_join(get_sentiments("bing")) %>%
count(date, index = order %/% 1000, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative) %>%
ggplot(aes(date, sentiment)) +
geom_point(alpha=0.5) +
geom_smooth(method= loess, alpha=0.25) +
ylab("bing sentiment")
tidy_tweets %>%
inner_join(get_sentiments("nrc")) %>%
count(date, index = order %/% 1000, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative) %>%
ggplot(aes(date, sentiment)) +
geom_point(alpha=0.5) +
geom_smooth(method= loess, alpha=0.25) +
ylab("nrc sentiment")
tidy_tweets %>%
inner_join(get_sentiments("afinn")) %>%
group_by(date, index = order %/% 1000) %>%
summarise(sentiment = sum(value)) %>%
ggplot(aes(date, sentiment)) +
geom_point(alpha=0.5) +
geom_smooth(method= loess, alpha=0.25) +
ylab("afinn sentiment")
word <- c('death', 'illness', 'hospital', 'life', 'health',
'fatality', 'morbidity', 'deadly', 'dead', 'victim')
value <- c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1)
mordict <- data.frame(word, value)
mordict
tidy_tweets %>%
inner_join(mordict) %>%
group_by(date, index = order %/% 1000) %>%
summarise(morwords = sum(value)) %>%
ggplot(aes(date, morwords)) +
geom_bar(stat= "identity") +
ylab("mortality words")
mordict <- c('death', 'illness', 'hospital', 'life', 'health',
'fatality', 'morbidity', 'deadly', 'dead', 'victim')
totals <- tidy_tweets %>%
mutate(obs=1) %>%
group_by(date) %>%
summarise(sum_words = sum(obs))
full_join(totals, word, by="date") %>%
mutate(sum_mwords= ifelse(is.na(sum_mwords), 0, sum_mwords),
pctmwords = sum_mwords/sum_words) %>%
ggplot(aes(date, pctmwords)) +
geom_point(alpha=0.5) +
geom_smooth(method= loess, alpha=0.25) +
xlab("Date") + ylab("% mortality words")
#plot
tidy_tweets %>%
mutate(obs=1) %>%
filter(grepl(paste0(mordict, collapse = "|"),word, ignore.case = T)) %>%
group_by(date) %>%
summarise(sum_mwords = sum(obs)) %>%
full_join(totals, word, by="date") %>%
mutate(sum_mwords= ifelse(is.na(sum_mwords), 0, sum_mwords),
pctmwords = sum_mwords/sum_words) %>%
ggplot(aes(date, pctmwords)) +
geom_point(alpha=0.5) +
geom_smooth(method= loess, alpha=0.25) +
xlab("Date") + ylab("% mortality words")
tweets$date <- as.Date(tweets$created_at)
tweet_corpus <- corpus(tweets, text_field = "tweet", docvars = "date")
toks_news <- tokens(tweet_corpus, remove_punct = TRUE)
toks_news <- tokens(tweet_corpus, remove_punct = TRUE)
# select only the "negative" and "positive" categories
data_dictionary_LSD2015_pos_neg <- data_dictionary_LSD2015[1:2]
toks_news_lsd <- tokens_lookup(toks_news, dictionary = data_dictionary_LSD2015_pos_neg)
dfmat_news_lsd <- dfm(toks_news_lsd) %>%
dfm_group(groups = date)
# plot positive and negative valence over time
matplot(dfmat_news_lsd$date, dfmat_news_lsd, type = "l", lty = 1, col = 1:2,
ylab = "Frequency", xlab = "")
grid()
library(lubridate)
matplot(dfmat_news_lsd$date, dfmat_news_lsd, type = "l", lty = 1, col = 1:2,
ylab = "Frequency", xlab = "")
grid()
legend("topleft", col = 1:2, legend = colnames(dfmat_news_lsd), lty = 1, bg = "white")
# create a document document-feature matrix and group it by date
dfmat_news_lsd <- dfm(toks_news_lsd) %>%
dfm_group(groups = date)
matplot(dfmat_news_lsd$date, dfmat_news_lsd, type = "l", lty = 1, col = 1:2,
ylab = "Frequency", xlab = "")
grid()
dfmat_news_lsd <- dfm(toks_news_lsd) %>%
dfm_group(groups = date)
# plot positive and negative valence over time
matplot(dfmat_news_lsd$date, dfmat_news_lsd, type = "l", lty = 1, col = 1:2,
ylab = "Frequency", xlab = "")
grid()
legend("topleft", col = 1:2, legend = colnames(dfmat_news_lsd), lty = 1, bg = "white")
# ===== 新增/修改的关键2步 =====
# 1. 提取日期（dfm分组后的文档名就是date）
dates <- as.Date(docnames(dfmat_news_lsd))
# 2. 把dfm转为普通数值矩阵（供matplot识别）
dfmat_values <- as.matrix(dfmat_news_lsd)
# plot positive and negative valence over time
matplot(dfmat_news_lsd$date, dfmat_news_lsd, type = "l", lty = 1, col = 1:2,
ylab = "Frequency", xlab = "")
grid()
legend("topleft", col = 1:2, legend = colnames(dfmat_news_lsd), lty = 1, bg = "white")
# create a document document-feature matrix and group it by date
dfmat_news_lsd <- dfm(toks_news_lsd) %>%
dfm_group(groups = date)
# ===== 新增/修改的关键2步 =====
# 1. 提取日期（dfm分组后的文档名就是date）
dates <- as.Date(docnames(dfmat_news_lsd))
# 2. 把dfm转为普通数值矩阵（供matplot识别）
dfmat_values <- as.matrix(dfmat_news_lsd)
# plot positive and negative valence over time
matplot(dfmat_news_lsd$date, dfmat_news_lsd, type = "l", lty = 1, col = 1:2,
ylab = "Frequency", xlab = "")
grid()
legend("topleft", col = 1:2, legend = colnames(dfmat_news_lsd), lty = 1, bg = "white")
plot(dfmat_news_lsd$date, dfmat_news_lsd[,"positive"] - dfmat_news_lsd[,"negative"],
type = "l", ylab = "Sentiment", xlab = "")
grid()
abline(h = 0, lty = 2)
# ===== 新增/修改的关键2步 =====
# 1. 提取日期（dfm分组后的文档名就是date）
dates <- as.Date(docnames(dfmat_news_lsd))
# 2. 把dfm转为普通数值矩阵（供matplot识别）
dfmat_values <- as.matrix(dfmat_news_lsd)
# plot positive and negative valence over time
matplot(dfmat_news_lsd$date, dfmat_news_lsd, type = "l", lty = 1, col = 1:2,
ylab = "Frequency", xlab = "")
grid()
legend("topleft", col = 1:2, legend = colnames(dfmat_news_lsd), lty = 1, bg = "white")
# create a document document-feature matrix and group it by date
dfmat_news_lsd <- dfm(toks_news_lsd) %>%
dfm_group(groups = date)
# ===== 新增/修改的关键2步 =====
# 1. 提取日期（dfm分组后的文档名就是date）
dates <- as.Date(docnames(dfmat_news_lsd))
# 2. 把dfm转为普通数值矩阵（供matplot识别）
dfmat_values <- as.matrix(dfmat_news_lsd)
# plot positive and negative valence over time
matplot(dfmat_news_lsd$date, dfmat_news_lsd, type = "l", lty = 1, col = 1:2,
ylab = "Frequency", xlab = "")
grid()
legend("topleft", col = 1:2, legend = colnames(dfmat_news_lsd), lty = 1, bg = "white")
# create a document document-feature matrix and group it by date
dfmat_news_lsd <- dfm(toks_news_lsd) %>%
dfm_group(groups = date)
# ===== 新增/修改的关键2步 =====
# 1. 提取日期（dfm分组后的文档名就是date）
dates <- as.Date(docnames(dfmat_news_lsd))
# 2. 把dfm转为普通数值矩阵（供matplot识别）
dfmat_values <- as.matrix(dfmat_news_lsd)
# plot positive and negative valence over time
matplot(dates, dfmat_values, type = "l", lty = 1, col = 1:2,
ylab = "Frequency", xlab = "Date")
grid()
legend("topleft", col = 1:2, legend = colnames(dfmat_values), lty = 1, bg = "white")
# plot overall sentiment (positive  - negative) over time
plot(dfmat_news_lsd$date, dfmat_news_lsd[,"positive"] - dfmat_news_lsd[,"negative"],
type = "l", ylab = "Sentiment", xlab = "")
grid()
abline(h = 0, lty = 2)
```{r}
negative <- dfmat_news_lsd@x[1:121]
positive <- dfmat_news_lsd@x[122:242]
date <- dfmat_news_lsd@Dimnames$docs
tidy_sent <- as.data.frame(cbind(negative, positive, date))
tidy_sent$negative <- as.numeric(tidy_sent$negative)
tidy_sent$positive <- as.numeric(tidy_sent$positive)
tidy_sent$sentiment <- tidy_sent$positive - tidy_sent$negative
tidy_sent$date <- as.Date(tidy_sent$date)
tidy_sent %>%
ggplot() +
geom_line(aes(date, sentiment))
# go back to token element and inspect docvars
docvars(toks_news) # ok all docvars are there
# look at how many different newspaper we have in the dataset
unique(docvars(toks_news)$username)
dfm_news_lsd <- dfm(toks_news_lsd) %>%
dfm_group(groups = username)
tidy_dfm_news_lsd <- dfm_news_lsd %>%
convert(to = "data.frame") %>%
rename("newspaper" = doc_id)
mutate(sentiment = positive - negative)
tidy_dfm_news_lsd <- dfm_news_lsd %>%
convert(to = "data.frame") %>%
rename("newspaper" = doc_id) %>% # when converting to data.frame, R called our grouping variable 'doc_id'. We rename it 'newspaper' instead.
mutate(sentiment = positive - negative) #
tidy_dfm_news_lsd %>%
ggplot() + # when we enter ggplot environment we need to use '+' not '%>%',
geom_point(aes(x=reorder(newspaper, -sentiment), y=sentiment)) + # reordering newspaper
# plot by newspaper
tidy_dfm_news_lsd %>%
ggplot() + # when we enter ggplot environment we need to use '+' not '%>%',
geom_point(aes(x=reorder(newspaper, -sentiment), y=sentiment)) + # reordering newspaper variable so it is displayed from most negative to most positive
coord_flip() + # pivot plot by 90 degrees
xlab("Newspapers") + # label x axis
ylab("Overall tweet sentiment (negative to positive)") + # label y axis
theme_minimal() # pretty graphic theme
tidy_dfm_news_lsd %>%
ggplot() + # when we enter ggplot environment we need to use '+' not '%>%',
geom_point(aes(x=reorder(newspaper, -sentiment), y=sentiment)) + # reordering newspaper variable so it is displayed from most negative to most positive
coord_flip() + # pivot plot by 90 degrees
xlab("Newspapers") + # label x axis
ylab("Overall tweet sentiment (negative to positive)") + # label y axis
theme_minimal() # pretty graphic theme
dfm_news_lsd <- dfm(toks_news_lsd) %>%
dfm_group(groups = interaction(username, date)) # we group by interaction variable between newspaper and date
# convert it to a dataframe so it's easier to use
tidy_dfm_news_lsd <- dfm_news_lsd %>%
convert(to = "data.frame")
head(tidy_dfm_news_lsd)
tidy_dfm_news_lsd <- tidy_dfm_news_lsd %>%
extract(doc_id, into = c("newspaper", "date"), regex = "([a-zA-Z]+)\\.(.+)") %>%
mutate(date = as.Date(date)) # clarify to R that this variable is a date
head(tidy_dfm_news_lsd)
tidy_dfm_news_lsd <- tidy_dfm_news_lsd %>%
mutate(sentiment = positive - negative)
tidy_dfm_news_lsd %>%
ggplot(aes(x=date, y=sentiment)) +
geom_point(alpha=0.5) + # plot points
geom_smooth(method= loess, alpha=0.25) + # plot smooth line
facet_wrap(~newspaper) + # 'facetting' means multiplying the plots so that there is one plot for each member of the group (here, sentiment) that way you can easily compare trend across group.
xlab("date") + ylab("overall sentiment (negative to positive)") +
ggtitle("Tweet sentiment trend across 8 British newspapers") +
theme_minimal()
trans_dict <- dictionary(list(trans = c('trans', 'transgender', 'trans rights', 'trans rights activists', 'LGBTQ', 'LGBTQ+'),
terf = c('transphobic', 'terf', 'terfs', 'transphobia', 'transphobes', 'gender critical')))
# back to tokens object
dfm_dict_trans <- toks_news %>%
tokens_lookup(dictionary = trans_dict) %>% # look up the occurrence of my dictionaries
dfm() %>% # turn into dfm
dfm_group(groups = username) %>% # group by newspaper
convert(to = "data.frame") %>% # convert it to a dataframe
rename("newspaper" = doc_id) %>% # rename variable
full_join(totals_newspaper, word, by="newspaper")
